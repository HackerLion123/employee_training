{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f75493a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_ollama\n",
      "  Downloading langchain_ollama-0.2.3-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.33 (from langchain_ollama)\n",
      "  Downloading langchain_core-0.3.33-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting ollama<1,>=0.4.4 (from langchain_ollama)\n",
      "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (1.33)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (0.3.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (2.10.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_ollama) (4.12.2)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from ollama<1,>=0.4.4->langchain_ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_ollama) (2.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\pagarwal\\onedrive - kmart australia limited\\desktop\\hackathon\\repo\\dandadan\\.venv\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (1.3.1)\n",
      "Downloading langchain_ollama-0.2.3-py3-none-any.whl (19 kB)\n",
      "Downloading langchain_core-0.3.33-py3-none-any.whl (412 kB)\n",
      "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama, langchain-core, langchain_ollama\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.32\n",
      "    Uninstalling langchain-core-0.3.32:\n",
      "      Successfully uninstalled langchain-core-0.3.32\n",
      "Successfully installed langchain-core-0.3.33 langchain_ollama-0.2.3 ollama-0.4.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b898c298-4160-444c-bafc-853d096c4230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "import chromadb\n",
    "import os\n",
    "\n",
    "# Define the LLM model to be used\n",
    "llm_model = \"phi3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79a6e711",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure ChromaDB\n",
    "# Initialize the ChromaDB client with persistent storage in the current directory\n",
    "chroma_client = chromadb.PersistentClient(path=os.path.join(os.getcwd(), \"chroma_db\"))\n",
    "\n",
    "# Define a custom embedding function for ChromaDB using Ollama\n",
    "class ChromaDBEmbeddingFunction:\n",
    "    \"\"\"\n",
    "    Custom embedding function for ChromaDB using embeddings from Ollama.\n",
    "    \"\"\"\n",
    "    def __init__(self, langchain_embeddings):\n",
    "        self.langchain_embeddings = langchain_embeddings\n",
    "\n",
    "    def __call__(self, input):\n",
    "        # Ensure the input is in a list format for processing\n",
    "        if isinstance(input, str):\n",
    "            input = [input]\n",
    "        return self.langchain_embeddings.embed_documents(input)\n",
    "\n",
    "# Initialize the embedding function with Ollama embeddings\n",
    "embedding = ChromaDBEmbeddingFunction(\n",
    "    OllamaEmbeddings(\n",
    "        model=llm_model,\n",
    "        base_url=\"http://localhost:11434\"  # Adjust the base URL as per your Ollama server configuration\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40b5d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a collection for the RAG workflow\n",
    "collection_name = \"rag_collection_demo_1\"\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=collection_name,\n",
    "    metadata={\"description\": \"A collection for RAG with Ollama - Demo1\"},\n",
    "    embedding_function=embedding  # Use the custom embedding function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "467ceaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: doc1\n",
      "Add of existing embedding ID: doc2\n",
      "Add of existing embedding ID: doc3\n",
      "Insert of existing embedding ID: doc1\n",
      "Insert of existing embedding ID: doc2\n",
      "Insert of existing embedding ID: doc3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to add documents to the ChromaDB collection\n",
    "def add_documents_to_collection(documents, ids):\n",
    "    \"\"\"\n",
    "    Add documents to the ChromaDB collection.\n",
    "    \n",
    "    Args:\n",
    "        documents (list of str): The documents to add.\n",
    "        ids (list of str): Unique IDs for the documents.\n",
    "    \"\"\"\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        ids=ids\n",
    "    )\n",
    "\n",
    "# Example: Add sample documents to the collection\n",
    "documents = [\n",
    "    \"Artificial intelligence is the simulation of human intelligence processes by machines.\",\n",
    "    \"Python is a programming language that lets you work quickly and integrate systems more effectively.\",\n",
    "    \"ChromaDB is a vector database designed for AI applications.\"\n",
    "]\n",
    "doc_ids = [\"doc1\", \"doc2\", \"doc3\"]\n",
    "\n",
    "# Documents only need to be added once or whenever an update is required. \n",
    "# This line of code is included for demonstration purposes:\n",
    "add_documents_to_collection(documents, doc_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8137fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to query the ChromaDB collection\n",
    "def query_chromadb(query_text, n_results=1):\n",
    "    \"\"\"\n",
    "    Query the ChromaDB collection for relevant documents.\n",
    "    \n",
    "    Args:\n",
    "        query_text (str): The input query.\n",
    "        n_results (int): The number of top results to return.\n",
    "    \n",
    "    Returns:\n",
    "        list of dict: The top matching documents and their metadata.\n",
    "    \"\"\"\n",
    "    results = collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    return results[\"documents\"], results[\"metadatas\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e954d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to interact with the Ollama LLM\n",
    "def query_ollama(prompt):\n",
    "    \"\"\"\n",
    "    Send a query to Ollama and retrieve the response.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The input prompt for Ollama.\n",
    "    \n",
    "    Returns:\n",
    "        str: The response from Ollama.\n",
    "    \"\"\"\n",
    "    llm = OllamaLLM(model=llm_model)\n",
    "    return llm.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7895af32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RAG pipeline: Combine ChromaDB and Ollama for Retrieval-Augmented Generation\n",
    "def rag_pipeline(query_text):\n",
    "    \"\"\"\n",
    "    Perform Retrieval-Augmented Generation (RAG) by combining ChromaDB and Ollama.\n",
    "    \n",
    "    Args:\n",
    "        query_text (str): The input query.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated response from Ollama augmented with retrieved context.\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve relevant documents from ChromaDB\n",
    "    retrieved_docs, metadata = query_chromadb(query_text)\n",
    "    context = \" \".join(retrieved_docs[0]) if retrieved_docs else \"No relevant documents found.\"\n",
    "\n",
    "    # Step 2: Send the query along with the context to Ollama\n",
    "    augmented_prompt = f\"Context: {context}\\n\\nQuestion: {query_text}\\nAnswer:\"\n",
    "    print(\"######## Augmented Prompt ########\")\n",
    "    print(augmented_prompt)\n",
    "\n",
    "    response = query_ollama(augmented_prompt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec7a7748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Augmented Prompt ########\n",
      "Context: ChromaDB is a vector database designed for AI applications.\n",
      "\n",
      "Question: What is artificial intelligence?\n",
      "Answer:\n",
      "######## Response from LLM ########\n",
      " Artificial Intelligence (AI) refers to the simulation of human-like processes by machines, particularly computer systems. It encompasses various technologies and methodologies that enable computers to learn from experience, adjust to new inputs, or perform tasks without explicit instructions. AI aims to create intelligent entities capable of performing complex tasks typically requiring human intellect â€“ such as understanding natural language, recognizing patterns in data, solving problems, making decisions, learning continuously, and even creativity. It's about enhancing the capabilities of computers so they can understand contextual nuances much like humans do within their respective domains or fields.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "# Define a query to test the RAG pipeline\n",
    "query = \"What is artificial intelligence?\"  # Change the query as needed\n",
    "response = rag_pipeline(query)\n",
    "print(\"######## Response from LLM ########\\n\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
